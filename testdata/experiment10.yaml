apiVersion: iter8.tools/v2alpha1
kind: Experiment
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"iter8.tools/v2alpha1","kind":"Experiment","metadata":{"annotations":{},"name":"experiment-1","namespace":"default"},"spec":{"criteria":{"indicators":["95th-percentile-tail-latency"],"objectives":[{"metric":"mean-latency","upperLimit":1000},{"metric":"error-rate","upperLimit":"0.01"}]},"duration":{"intervalSeconds":15,"maxIterations":10},"strategy":{"type":"Canary"},"target":"default/my-model"}}
  creationTimestamp: "2021-01-10T14:39:47Z"
  generation: 3
  name: experiment-1
  namespace: default
  resourceVersion: "24530"
  selfLink: /apis/iter8.tools/v2alpha1/namespaces/default/experiments/experiment-1
  uid: 0b4e4301-2eed-404e-b625-2e47fb85a703
spec:
  criteria:
    indicators:
    - 95th-percentile-tail-latency
    objectives:
    - metric: mean-latency
      upperLimit: 1k
    - metric: error-rate
      upperLimit: 10m
    requestCount: request-count
  duration:
    intervalSeconds: 15
    maxIterations: 10
  metrics:
  - metricObj:
      apiVersion: iter8.tools/v2alpha1
      kind: Metric
      metadata:
        annotations:
          kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"iter8.tools/v2alpha1","kind":"Metric","metadata":{"annotations":{},"name":"request-count","namespace":"iter8-system"},"spec":{"description":"Number of requests","params":{"query":"sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval])) or on() vector(0)"},"provider":"prometheus","type":"counter"}}
        creationTimestamp: "2021-01-10T12:39:24Z"
        generation: 1
        name: request-count
        namespace: iter8-system
        resourceVersion: "5297"
        selfLink: /apis/iter8.tools/v2alpha1/namespaces/iter8-system/metrics/request-count
        uid: be4b1e71-e537-4f7d-9fb1-209ed35cfabe
      spec:
        description: Number of requests
        params:
          query: sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval]))
            or on() vector(0)
        provider: prometheus
        type: counter
    name: request-count
  - metricObj:
      apiVersion: iter8.tools/v2alpha1
      kind: Metric
      metadata:
        annotations:
          kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"iter8.tools/v2alpha1","kind":"Metric","metadata":{"annotations":{},"name":"95th-percentile-tail-latency","namespace":"iter8-system"},"spec":{"description":"95th percentile tail latency","params":{"query":"histogram_quantile(0.95, sum(rate(revision_app_request_latencies_bucket{revision_name='$revision'}[$interval])) by (le))"},"provider":"prometheus","sample_size":{"name":"request-count"},"type":"gauge","units":"milliseconds"}}
        creationTimestamp: "2021-01-10T12:39:24Z"
        generation: 1
        name: 95th-percentile-tail-latency
        namespace: iter8-system
        resourceVersion: "5293"
        selfLink: /apis/iter8.tools/v2alpha1/namespaces/iter8-system/metrics/95th-percentile-tail-latency
        uid: 2d2ef203-a1cd-4779-b5dd-0f6d1a53007a
      spec:
        description: 95th percentile tail latency
        params:
          query: histogram_quantile(0.95, sum(rate(revision_app_request_latencies_bucket{revision_name='$revision'}[$interval]))
            by (le))
        provider: prometheus
        sample_size:
          name: request-count
        type: gauge
        units: milliseconds
    name: 95th-percentile-tail-latency
  - metricObj:
      apiVersion: iter8.tools/v2alpha1
      kind: Metric
      metadata:
        annotations:
          kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"iter8.tools/v2alpha1","kind":"Metric","metadata":{"annotations":{},"name":"mean-latency","namespace":"iter8-system"},"spec":{"description":"Mean latency","params":{"query":"(sum(increase(revision_app_request_latencies_sum{revision_name='$revision'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval])) or on() vector(0))"},"provider":"prometheus","sample_size":{"name":"request-count"},"type":"gauge","units":"milliseconds"}}
        creationTimestamp: "2021-01-10T12:39:24Z"
        generation: 1
        name: mean-latency
        namespace: iter8-system
        resourceVersion: "5296"
        selfLink: /apis/iter8.tools/v2alpha1/namespaces/iter8-system/metrics/mean-latency
        uid: aa1a9a1a-f430-40f3-8ca6-098622b73388
      spec:
        description: Mean latency
        params:
          query: (sum(increase(revision_app_request_latencies_sum{revision_name='$revision'}[$interval]))or
            on() vector(0)) / (sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval]))
            or on() vector(0))
        provider: prometheus
        sample_size:
          name: request-count
        type: gauge
        units: milliseconds
    name: mean-latency
  - metricObj:
      apiVersion: iter8.tools/v2alpha1
      kind: Metric
      metadata:
        annotations:
          kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"iter8.tools/v2alpha1","kind":"Metric","metadata":{"annotations":{},"name":"error-rate","namespace":"iter8-system"},"spec":{"description":"Fraction of requests with error responses","params":{"query":"(sum(increase(revision_app_request_latencies_count{response_code_class!='2xx',revision_name='$revision'}[$interval])) or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval])) or on() vector(0))"},"provider":"prometheus","sample_size":{"name":"request-count"},"type":"gauge"}}
        creationTimestamp: "2021-01-10T12:39:24Z"
        generation: 1
        name: error-rate
        namespace: iter8-system
        resourceVersion: "5295"
        selfLink: /apis/iter8.tools/v2alpha1/namespaces/iter8-system/metrics/error-rate
        uid: ac134e24-017b-426d-80d7-b03bdfab2b6e
      spec:
        description: Fraction of requests with error responses
        params:
          query: (sum(increase(revision_app_request_latencies_count{response_code_class!='2xx',revision_name='$revision'}[$interval]))
            or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{revision_name='$revision'}[$interval]))
            or on() vector(0))
        provider: prometheus
        sample_size:
          name: request-count
        type: gauge
    name: error-rate
  strategy:
    handlers:
      failure: finish
      finish: finish
      rollback: finish
      start: start
    type: Canary
    weights:
      algorithm: Progressive
      maxCandidateWeight: 100
      maxCandidateWeightIncrement: 10
  target: default/my-model
  versionInfo:
    baseline:
      name: default
      tags:
        revision: my-model-predictor-default-dlgm8
    candidates:
    - name: canary
      tags:
        revision: my-model-predictor-default-h4bvl
      weightObjRef:
        apiVersion: serving.kubeflow.org/v1beta1
        fieldPath: /spec/predictor/canaryTrafficPercent
        kind: InferenceService
        name: my-model
        namespace: default
status:
  analysis:
    aggregatedMetrics:
      data:
        95th-percentile-tail-latency:
          data:
            canary: {}
            default: {}
        error-rate:
          data:
            canary: {}
            default: {}
        mean-latency:
          data:
            canary: {}
            default: {}
        request-count:
          data:
            canary: {}
            default: {}
      message: 'Error: Error from metrics backend for metric: request-count and version:
        default, Error from metrics backend for metric: request-count and version:
        canary, Error from metrics backend for metric: 95th-percentile-tail-latency
        and version: default, Error from metrics backend for metric: 95th-percentile-tail-latency
        and version: canary, Error from metrics backend for metric: mean-latency and
        version: default, Error from metrics backend for metric: mean-latency and
        version: canary, Error from metrics backend for metric: error-rate and version:
        default, Error from metrics backend for metric: error-rate and version: canary;
        Warning: ; Info: '
      provenance: http://iter8-analytics:8080/v2/analytics_results
      timestamp: "2021-01-10T14:40:36Z"
    versionAssessments:
      data:
        canary:
        - false
        - false
        default:
        - false
        - false
      message: 'Error: ; Warning: Value for mean-latency metric and default version
        is None., Value for mean-latency metric and canary version is None., Value
        for error-rate metric and default version is None., Value for error-rate metric
        and canary version is None.; Info: '
      provenance: http://iter8-analytics:8080/v2/analytics_results
      timestamp: "2021-01-10T14:40:36Z"
    weights:
      data:
      - name: default
        value: 95
      - name: canary
        value: 5
      message: 'Error: ; Warning: ; Info: all ok'
      provenance: http://iter8-analytics:8080/v2/analytics_results
      timestamp: "2021-01-10T14:40:36Z"
    winnerAssessment:
      data:
        winnerFound: false
      provenance: http://iter8-analytics:8080/v2/analytics_results
      timestamp: "2021-01-10T14:40:36Z"
  completedIterations: 3
  conditions:
  - lastTransitionTime: "2021-01-10T14:40:39Z"
    message: Completed Iteration 3
    reason: IterationUpdate
    status: "False"
    type: ExperimentCompleted
  - lastTransitionTime: "2021-01-10T14:39:47Z"
    status: "False"
    type: ExperimentFailed
  currentWeightDistribution:
  - name: default
    value: 95
  - name: canary
    value: 5
  initTime: "2021-01-10T14:39:47Z"
  lastUpdateTime: "2021-01-10T14:40:39Z"
  message: 'IterationUpdate: Completed Iteration 3'
  recommendedBaseline: default
  startTime: "2021-01-10T14:40:00Z"
